{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from sacred import Experiment\n",
    "from sacred.observers import MongoObserver, FileStorageObserver\n",
    "\n",
    "ex = Experiment(\"notebook-keras-sacred\", interactive=True)\n",
    "\n",
    "ex.observers.append(FileStorageObserver(\"cnn2-experiment\"))\n",
    "# Uncomment to add MongoDB support \n",
    "#ex.observers.append(MongoObserver(url=\"mongodb://<user>:<password>@<hostname>:<port>/<auth-db>\", db_name=\"<sacred-db>\"))\n",
    "\n",
    "\n",
    "@ex.config\n",
    "def cfg():\n",
    "    batch_size = 64\n",
    "    num_epochs = 10\n",
    "    learning_rate = 0.01\n",
    "\n",
    "\n",
    "class MetricsLoggerCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, _run):\n",
    "        super().__init__()\n",
    "        self._run = _run\n",
    "\n",
    "    def on_epoch_end(self, _, logs):\n",
    "        self._run.log_scalar(\"training.loss\", logs.get('loss'))\n",
    "        self._run.log_scalar(\"training.acc\", logs.get('accuracy'))\n",
    "        self._run.log_scalar(\"validation.loss\", logs.get('val_loss'))\n",
    "        self._run.log_scalar(\"validation.acc\", logs.get('val_accuracy'))\n",
    "\n",
    "@ex.main\n",
    "def run(_run, batch_size, num_epochs, learning_rate):\n",
    "    \n",
    "    # importing the dataset\n",
    "    fashion_mnist = keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "    # normalizing the images to 0 and 1\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "\n",
    "    # setting up the model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # compiling the model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # training the model\n",
    "    model.fit(train_images, train_labels,\n",
    "            batch_size=batch_size,\n",
    "            epochs=num_epochs,\n",
    "            validation_data=(test_images, test_labels),\n",
    "            callbacks=[MetricsLoggerCallback(_run)],\n",
    "            verbose=2)\n",
    "\n",
    "    # evaluating the model\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "    ex.log_scalar(\"test loss\", test_loss)\n",
    "    ex.log_scalar(\"test acc\", test_acc)\n",
    "    print('Test loss:', test_loss, ' and Test accuracy:', test_acc)\n",
    "    \n",
    "    # We also can store our trained model\n",
    "    # pickle.dump(model, open(\"mymodel.p\", \"wb\"))\n",
    "    # ex.add_artifact(\"mymodel.p\")\n",
    "\n",
    "    \n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - notebook-keras-sacred - Running command 'run'\n",
      "INFO - notebook-keras-sacred - Started run with ID \"8\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 1s - loss: 1.7796 - accuracy: 0.6805 - val_loss: 1.7307 - val_accuracy: 0.7299\n",
      "Epoch 2/10\n",
      "938/938 - 1s - loss: 1.7137 - accuracy: 0.7468 - val_loss: 1.7144 - val_accuracy: 0.7458\n",
      "Epoch 3/10\n",
      "938/938 - 1s - loss: 1.7097 - accuracy: 0.7509 - val_loss: 1.7227 - val_accuracy: 0.7379\n",
      "Epoch 4/10\n",
      "938/938 - 1s - loss: 1.7070 - accuracy: 0.7536 - val_loss: 1.6955 - val_accuracy: 0.7653\n",
      "Epoch 5/10\n",
      "938/938 - 1s - loss: 1.7017 - accuracy: 0.7589 - val_loss: 1.7358 - val_accuracy: 0.7248\n",
      "Epoch 6/10\n",
      "938/938 - 1s - loss: 1.7039 - accuracy: 0.7569 - val_loss: 1.7014 - val_accuracy: 0.7597\n",
      "Epoch 7/10\n",
      "938/938 - 1s - loss: 1.7075 - accuracy: 0.7533 - val_loss: 1.7075 - val_accuracy: 0.7537\n",
      "Epoch 8/10\n",
      "938/938 - 1s - loss: 1.7030 - accuracy: 0.7579 - val_loss: 1.7133 - val_accuracy: 0.7477\n",
      "Epoch 9/10\n",
      "938/938 - 1s - loss: 1.7141 - accuracy: 0.7469 - val_loss: 1.7299 - val_accuracy: 0.7316\n",
      "Epoch 10/10\n",
      "938/938 - 1s - loss: 1.7030 - accuracy: 0.7579 - val_loss: 1.7029 - val_accuracy: 0.7583\n",
      "313/313 - 0s - loss: 1.7029 - accuracy: 0.7583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - notebook-keras-sacred - Result: 0.7583000063896179\n",
      "INFO - notebook-keras-sacred - Completed after 0:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.7028793096542358  and Test accuracy: 0.7583000063896179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sacred.run.Run at 0x7f41cc6a1b90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex\n",
    "ex.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml37] *",
   "language": "python",
   "name": "conda-env-ml37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
